# ğŸ“˜ PySpark Projects & Examples Repository

Explanation of all PySpark RDD, DataFrame and SQL examples present in this project are available at  
ğŸ‘‰ **[Apache PySpark Tutorial](https://sparkbyexamples.com/pyspark-tutorial/)**  
All these examples are coded in Python language and tested in a local development environment using PySpark.

---

# ğŸ§­ Table of Contents

1. [PySpark Basic Examples](#pyspark-basic-examples)  
2. [PySpark DataFrame Examples](#pyspark-dataframe-examples)  
3. [PySpark SQL Functions](#pyspark-sql-functions)  
4. [PySpark Datasources](#pyspark-datasources)  
5. [End-to-End PySpark Projects (Beginner â†’ Intermediate)](#end-to-end-pyspark-projects)

---

# ğŸ”¹ PySpark Basic Examples

- How to create SparkSession  
- PySpark â€“ Accumulator  
- PySpark â€“ Repartition vs Coalesce  
- PySpark â€“ Broadcast variables  
- PySpark â€“ `repartition()` vs `coalesce()`  
- PySpark â€“ Parallelize  
- PySpark â€“ RDD  
- PySpark â€“ Web/Application UI  
- PySpark â€“ SparkSession  
- PySpark â€“ Cluster Managers  
- PySpark â€“ Install on Windows  
- PySpark â€“ Modules & Packages  
- PySpark â€“ Advantages  
- PySpark â€“ Features  
- PySpark â€“ What is it? & Who uses it?

---

# ğŸ”¹ PySpark DataFrame Examples

- PySpark â€“ Create a DataFrame  
- PySpark â€“ Create an empty DataFrame  
- PySpark â€“ Convert RDD to DataFrame  
- PySpark â€“ Convert DataFrame to Pandas  
- PySpark â€“ StructType & StructField  
- PySpark â€“ Using Row on DataFrame and RDD  
- Select columns from PySpark DataFrame  
- PySpark `collect()` â€“ Retrieve full data  
- PySpark `withColumn()` to update/add columns  
- PySpark `where` filter function  
- PySpark `distinct()` to drop duplicates  
- PySpark `orderBy()` and `sort()` explained  
- PySpark `groupBy()` with examples  
- PySpark Join types explained  
- PySpark Union and UnionAll  
- PySpark UDF (User Defined Functions)  
- PySpark `flatMap()` transformation  
- PySpark `map()` transformation  

---

# ğŸ”¹ PySpark SQL Functions

- PySpark Aggregate Functions  
- PySpark Window Functions  

---

# ğŸ”¹ PySpark Datasources

- Read CSV into DataFrame  
- Read & Write Parquet Files  

---

# ğŸš€ End-to-End PySpark Projects

This section contains real-world projects built using PySpark. They cover beginner to intermediate levels and are suitable for practicing **ETL, analytics, RDDs, DataFrames, SQL, and Big Data concepts**.

---

## 1ï¸âƒ£ Movie Ratings Analysis (Beginner â€” DataFrames)

**Dataset:** MovieLens Small Dataset  
**Skills:** DataFrames, joins, aggregations

### ğŸ“Œ Tasks
- Load `movies.csv` and `ratings.csv`
- Top 10 highest-rated movies  
- Most-rated movies  
- Average rating per genre  
- Most active users  

**Spark Concepts:**  
`select`, `filter`, `groupBy`, `agg`, `orderBy`, joins

---

## 2ï¸âƒ£ Apache Log File Analyzer (Beginner â€” RDD + DataFrame)

**Dataset:** Apache access.log  
**Skills:** RDD parsing, regex extraction

### ğŸ“Œ Tasks
- Count total requests  
- Count hits per URL  
- Extract IP addresses  
- Peak traffic hour  

**Spark Concepts:**  
RDD â†’ DataFrame conversion, `map`, `filter`, `reduceByKey`, SQL queries

---

## 3ï¸âƒ£ Retail Sales ETL Pipeline (Intermediate â€” DataFrames)

**Dataset:** Kaggle Retail Sales  
**Skills:** Data cleaning, ETL, aggregations

### ğŸ“Œ Steps
- Read CSV from local/S3  
- Clean missing values  
- Normalize data types  
- Enrich with profit & margin  
- Aggregate by region, category, segment  
- Write clean data to Parquet  

**Spark Concepts:**  
ETL pipeline, window functions, Parquet writing, partitioning

---

## 4ï¸âƒ£ NYC Taxi Trip Analytics (Intermediate â€” Big Data)

**Dataset:** NYC Taxi Trip Data  
**Skills:** Big Data analytics, Parquet optimization

### ğŸ“Œ Tasks
- Load multi-GB taxi parquet data  
- Avg trip distance & fare per borough  
- Peak pickup hours  
- Outlier detection  

**Spark Concepts:**  
Predicate pushdown, column pruning, large DataFrame optimization

---

## 5ï¸âƒ£ Airbnb Price Predictor (MLlib)

**Dataset:** Airbnb Listings  
**Skills:** Machine Learning with Spark MLlib

### ğŸ“Œ Build
- Clean dataset  
- One-hot encoding  
- Train ML pipeline  
- Predict price using Linear Regression or Random Forest  
- Evaluate RMSE  

**Spark Concepts:**  
VectorAssembler, ML Pipelines, train-test split

---

## 6ï¸âƒ£ Real-Time Streaming Log Processor (Structured Streaming)

**Dataset:** Kafka â†’ Spark Streaming  
**Skills:** Real-time pipelines

### ğŸ“Œ Workflow
- Kafka producer â†’ JSON logs  
- Spark Streaming processes logs  
- Compute:
  - Event count  
  - Errors per minute  
  - Avg response time  
- Output results to console/parquet  

**Spark Concepts:**  
Structured Streaming, window aggregations, triggers

---

## 7ï¸âƒ£ YouTube/Twitter Trending Analysis (API + PySpark)

**Dataset:** YouTube/Twitter API  
**Skills:** JSON ingestion + analysis

### ğŸ“Œ Tasks
- Fetch trending videos/tweets  
- Normalize nested JSON  
- Extract:
  - Most-used hashtags  
  - Trending categories  
  - Top creators  

**Spark Concepts:**  
`explode`, nested JSON parsing, aggregations

---

# ğŸ¯ Repository Goal

This repository is designed to act as a **complete learning tracker** for PySpark, covering:

âœ” RDDs  
âœ” DataFrames  
âœ” SQL & Window functions  
âœ” ETL Pipelines  
âœ” Big Data projects  
âœ” Streaming  
âœ” Machine Learning  
